{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import string\n",
    "from datetime import datetime\n",
    "import findspark \n",
    "findspark.init()\n",
    "import pyspark as ps\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import array_contains, col, udf, when, coalesce, array\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, CountVectorizer, IDFModel, StopWordsRemover\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, ParamGridBuilder, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = ps.sql.SparkSession.builder \\\n",
    "            .master(\"local[4]\") \\\n",
    "            .appName('Model Training') \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "        StructField('NewIndex' , IntegerType(), False),\n",
    "        StructField('Index' , IntegerType(), False),\n",
    "        StructField('ItemID' , IntegerType(), False),\n",
    "        StructField('Sentiment' , IntegerType(), False),\n",
    "        StructField('SentimentSource' , StringType(), False),\n",
    "        StructField('SentimentText' , StringType(), False),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NewIndex: integer (nullable = true)\n",
      " |-- Index: integer (nullable = true)\n",
      " |-- ItemID: integer (nullable = true)\n",
      " |-- Sentiment: integer (nullable = true)\n",
      " |-- SentimentSource: string (nullable = true)\n",
      " |-- SentimentText: string (nullable = true)\n",
      "\n",
      "+--------+-----+------+---------+---------------+--------------------+\n",
      "|NewIndex|Index|ItemID|Sentiment|SentimentSource|       SentimentText|\n",
      "+--------+-----+------+---------+---------------+--------------------+\n",
      "|       0|    0|     1|        0|   Sentiment140|                 ...|\n",
      "|       1|    1|     2|        0|   Sentiment140|                 ...|\n",
      "|       2|    2|     3|        1|   Sentiment140|              omg...|\n",
      "|       3|    3|     4|        0|   Sentiment140|          .. Omga...|\n",
      "|       4|    4|     5|        0|   Sentiment140|         i think ...|\n",
      "+--------+-----+------+---------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"../data/nokaggle-Sentiment-Analysis-Dataset.csv\"\n",
    "users = spark.read.csv(filename, header=True, schema=schema)\n",
    "users.printSchema()\n",
    "users.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    words = re.sub(\"[^a-zA-Z]\", \" \", text).lower().split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NewIndex: integer (nullable = true)\n",
      " |-- Index: integer (nullable = true)\n",
      " |-- ItemID: integer (nullable = true)\n",
      " |-- Sentiment: integer (nullable = true)\n",
      " |-- SentimentSource: string (nullable = true)\n",
      " |-- SentimentText: string (nullable = true)\n",
      " |-- Words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp_udf = udf(preprocess, ArrayType(StringType()))\n",
    "words = users.withColumn('Words', pp_udf(users.SentimentText))\n",
    "words.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+---------+---------------+--------------------+--------------------+--------------------+\n",
      "|NewIndex|Index|ItemID|Sentiment|SentimentSource|       SentimentText|               Words|            filtered|\n",
      "+--------+-----+------+---------+---------------+--------------------+--------------------+--------------------+\n",
      "|       0|    0|     1|        0|   Sentiment140|                 ...|[is, so, sad, for...|  [sad, apl, friend]|\n",
      "|       1|    1|     2|        0|   Sentiment140|                 ...|[i, missed, the, ...|[missed, new, moo...|\n",
      "|       2|    2|     3|        1|   Sentiment140|              omg...|[omg, its, alread...|      [omg, already]|\n",
      "|       3|    3|     4|        0|   Sentiment140|          .. Omga...|[omgaga, im, sooo...|[omgaga, im, sooo...|\n",
      "|       4|    4|     5|        0|   Sentiment140|         i think ...|[i, think, mi, bf...|[think, mi, bf, c...|\n",
      "|       5|    5|     6|        0|   Sentiment140|         or i jus...|[or, i, just, wor...|       [worry, much]|\n",
      "|       6|    6|     7|        1|   Sentiment140|       Juuuuuuuuu...|[juuuuuuuuuuuuuuu...|[juuuuuuuuuuuuuuu...|\n",
      "|       7|    7|     8|        0|   Sentiment140|       Sunny Agai...|[sunny, again, wo...|[sunny, work, tom...|\n",
      "|       8|    8|     9|        1|   Sentiment140|      handed in m...|[handed, in, my, ...|[handed, uniform,...|\n",
      "|       9|    9|    10|        1|   Sentiment140|      hmmmm.... i...|[hmmmm, i, wonder...|[hmmmm, wonder, n...|\n",
      "|      10|   10|    11|        0|   Sentiment140|      I must thin...|[i, must, think, ...|[must, think, pos...|\n",
      "|      11|   11|    12|        1|   Sentiment140|      thanks to a...|[thanks, to, all,...|[thanks, haters, ...|\n",
      "|      12|   12|    13|        0|   Sentiment140|      this weeken...|[this, weekend, h...|[weekend, sucked,...|\n",
      "|      13|   13|    14|        0|   Sentiment140|     jb isnt show...|[jb, isnt, showin...|[jb, isnt, showin...|\n",
      "|      14|   14|    15|        0|   Sentiment140|     ok thats it ...|[ok, thats, it, y...|    [ok, thats, win]|\n",
      "|      15|   15|    16|        0|   Sentiment140|    &lt;-------- ...|[lt, this, is, th...|[lt, way, feel, r...|\n",
      "|      16|   16|    17|        0|   Sentiment140|    awhhe man.......|[awhhe, man, i, m...|[awhhe, man, comp...|\n",
      "|      17|   17|    18|        1|   Sentiment140|    Feeling stran...|[feeling, strange...|[feeling, strange...|\n",
      "|      18|   18|    19|        0|   Sentiment140|    HUGE roll of ...|[huge, roll, of, ...|[huge, roll, thun...|\n",
      "|      19|   19|    20|        0|   Sentiment140|    I just cut my...|[i, just, cut, my...|[cut, beard, grow...|\n",
      "+--------+-----+------+---------+---------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"Words\", outputCol=\"filtered\")\n",
    "removed = remover.transform(words)\n",
    "removed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------------------+--------------------+--------------------+\n",
      "|ItemID|label|       SentimentText|               Words|            filtered|\n",
      "+------+-----+--------------------+--------------------+--------------------+\n",
      "|     1|    0|                 ...|[is, so, sad, for...|  [sad, apl, friend]|\n",
      "|     2|    0|                 ...|[i, missed, the, ...|[missed, new, moo...|\n",
      "|     3|    1|              omg...|[omg, its, alread...|      [omg, already]|\n",
      "|     4|    0|          .. Omga...|[omgaga, im, sooo...|[omgaga, im, sooo...|\n",
      "|     5|    0|         i think ...|[i, think, mi, bf...|[think, mi, bf, c...|\n",
      "|     6|    0|         or i jus...|[or, i, just, wor...|       [worry, much]|\n",
      "|     7|    1|       Juuuuuuuuu...|[juuuuuuuuuuuuuuu...|[juuuuuuuuuuuuuuu...|\n",
      "|     8|    0|       Sunny Agai...|[sunny, again, wo...|[sunny, work, tom...|\n",
      "|     9|    1|      handed in m...|[handed, in, my, ...|[handed, uniform,...|\n",
      "|    10|    1|      hmmmm.... i...|[hmmmm, i, wonder...|[hmmmm, wonder, n...|\n",
      "|    11|    0|      I must thin...|[i, must, think, ...|[must, think, pos...|\n",
      "|    12|    1|      thanks to a...|[thanks, to, all,...|[thanks, haters, ...|\n",
      "|    13|    0|      this weeken...|[this, weekend, h...|[weekend, sucked,...|\n",
      "|    14|    0|     jb isnt show...|[jb, isnt, showin...|[jb, isnt, showin...|\n",
      "|    15|    0|     ok thats it ...|[ok, thats, it, y...|    [ok, thats, win]|\n",
      "|    16|    0|    &lt;-------- ...|[lt, this, is, th...|[lt, way, feel, r...|\n",
      "|    17|    0|    awhhe man.......|[awhhe, man, i, m...|[awhhe, man, comp...|\n",
      "|    18|    1|    Feeling stran...|[feeling, strange...|[feeling, strange...|\n",
      "|    19|    0|    HUGE roll of ...|[huge, roll, of, ...|[huge, roll, thun...|\n",
      "|    20|    0|    I just cut my...|[i, just, cut, my...|[cut, beard, grow...|\n",
      "+------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered = removed.select('ItemID', col('Sentiment').alias('label'), 'SentimentText', 'Words', 'filtered')\n",
    "filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ItemID: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- SentimentText: string (nullable = true)\n",
      " |-- Words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cast empty array \n",
    "\n",
    "fill = array().cast(\"array<string>\")\n",
    "filtered_filled = coalesce(col(\"filtered\"), fill)\n",
    "filled_featurized = filtered.withColumn(\"filtered\", filtered_filled)\n",
    "filled_featurized.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|rawFeatures                                                                                          |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|(200,[38,60,193],[1.0,1.0,1.0])                                                                      |\n",
      "|(200,[15,25,81,196],[1.0,1.0,1.0,1.0])                                                               |\n",
      "|(200,[57,184],[1.0,1.0])                                                                             |\n",
      "|(200,[18,56,73,82,102,132,150,155,159,166,169,185],[1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|(200,[72,164,165,169],[1.0,1.0,1.0,1.0])                                                             |\n",
      "|(200,[124,162],[1.0,1.0])                                                                            |\n",
      "|(200,[9,190],[1.0,1.0])                                                                              |\n",
      "|(200,[25,50,101,118,127],[1.0,1.0,1.0,1.0,1.0])                                                      |\n",
      "|(200,[57,62,71,191,197],[1.0,1.0,1.0,1.0,1.0])                                                       |\n",
      "|(200,[84,98,183],[1.0,1.0,1.0])                                                                      |\n",
      "|(200,[1,23,164],[1.0,1.0,1.0])                                                                       |\n",
      "|(200,[5,30,34,138],[1.0,1.0,1.0,1.0])                                                                |\n",
      "|(200,[90,102,186],[1.0,1.0,1.0])                                                                     |\n",
      "|(200,[2,17,116,176],[1.0,1.0,1.0,1.0])                                                               |\n",
      "|(200,[50,84,116],[1.0,1.0,1.0])                                                                      |\n",
      "|(200,[115,134,159,174],[1.0,1.0,1.0,1.0])                                                            |\n",
      "|(200,[22,30,33,65,76,89,106,131,132,187],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                  |\n",
      "|(200,[31,35,41,63,77,88,162,167],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                  |\n",
      "|(200,[4,14,74,198],[1.0,1.0,1.0,1.0])                                                                |\n",
      "|(200,[27,59,63,99,141,153,157,161,196,198],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=200)\n",
    "featurized = hashingTF.transform(filled_featurized)\n",
    "featurized.select('rawFeatures').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                                                                                                                                                                                          |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(200,[38,60,193],[3.351292892234358,2.7425253655359136,3.2069298628197354])                                                                                                                                                                                                       |\n",
      "|(200,[15,25,81,196],[3.5302978401981506,2.5787462546945012,3.806789299182284,3.230943760152062])                                                                                                                                                                                  |\n",
      "|(200,[57,184],[3.4062058773194526,3.4811037871503667])                                                                                                                                                                                                                            |\n",
      "|(200,[18,56,73,82,102,132,150,155,159,166,169,185],[3.730004761243489,3.499232427988505,3.2076348991583097,5.932750901186225,3.707378652330693,3.2164347103690063,3.1296341759598167,3.2611049833609256,2.357975445745883,4.054514900232662,3.8269361048587265,3.388715924244202])|\n",
      "|(200,[72,164,165,169],[3.2171623052256915,2.6045128481045268,3.225775376524396,3.8269361048587265])                                                                                                                                                                               |\n",
      "|(200,[124,162],[3.236187374489301,3.750669742661097])                                                                                                                                                                                                                             |\n",
      "|(200,[9,190],[3.515987632738829,3.936845597871823])                                                                                                                                                                                                                               |\n",
      "|(200,[25,50,101,118,127],[2.5787462546945012,3.111831853786621,3.1197958080613817,3.6196570984771834,2.745956847791588])                                                                                                                                                          |\n",
      "|(200,[57,62,71,191,197],[3.4062058773194526,2.607716341188582,2.945273045924273,3.5352007679067667,3.4351017754415927])                                                                                                                                                           |\n",
      "|(200,[84,98,183],[3.2116237858330487,3.6251385145864248,3.3895803747142854])                                                                                                                                                                                                      |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurized.cache()\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "model = idf.fit(featurized)\n",
    "result = model.transform(featurized)\n",
    "result.limit(10).select('features').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save idf and idf model\n",
    "idf_path = '../tmp/idf'\n",
    "idf.save(idf_path)\n",
    "idfmodel_path = '../tmp/idfmodel'\n",
    "model.save(idfmodel_path)\n",
    "#load via following\n",
    "#loadedModel = IDFModel.load(idfmodel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32 ms, sys: 0 ns, total: 32 ms\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(numTrees=100, labelCol=\"label\", seed=42)\n",
    "rf_model = rf.fit(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SentimentText: string (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+----------+\n",
      "|       SentimentText|         probability|prediction|\n",
      "+--------------------+--------------------+----------+\n",
      "|                 ...|[0.50464022409798...|       0.0|\n",
      "|              omg...|[0.49997696970661...|       1.0|\n",
      "|          .. Omga...|[0.51373803403465...|       0.0|\n",
      "|     jb isnt show...|[0.49997696970661...|       1.0|\n",
      "|    awhhe man.......|[0.48503937730438...|       1.0|\n",
      "+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 220 ms, sys: 48 ms, total: 268 ms\n",
      "Wall time: 7min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Prepare Train Test Split\n",
    "train, test = result.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Configure an ML pipeline, which consists of tree stages: hashingTF, idf and RandomForestClassifier.\n",
    "#remover = StopWordsRemover(inputCol=\"Words\", outputCol=\"filtered\")\n",
    "#hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "rf = RandomForestClassifier(labelCol=\"label\", seed=42)\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "#grid search\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [100]).addGrid(rf.maxDepth, [5]).build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3)  # use 3+ folds in practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(test)\n",
    "selected = prediction.select(\"SentimentText\", \"probability\", \"prediction\")\n",
    "selected.printSchema()\n",
    "selected.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.645381227448802]\n"
     ]
    }
   ],
   "source": [
    "print (cvModel.avgMetrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
