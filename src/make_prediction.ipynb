{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pymongo\n",
    "import findspark \n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql.functions import col, udf\n",
    "import pymongo_spark\n",
    "pymongo_spark.activate()\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, CountVectorizer, IDFModel, StopWordsRemover\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression, GBTClassifier, RandomForestClassificationModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, ParamGridBuilder, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "            .master(\"local[4]\") \\\n",
    "            .appName('Testing Spark Mongo') \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "people = spark.createDataFrame([(\"Bilbo Baggins\",  50), (\"Gandalf\", 1000), (\"Thorin\", 195), (\"Balin\", 178), (\"Kili\", 77),\n",
    "   (\"Dwalin\", 169), (\"Oin\", 167), (\"Gloin\", 158), (\"Fili\", 82), (\"Bombur\", None)], [\"name\", \"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+\n",
      "|         name| age|\n",
      "+-------------+----+\n",
      "|Bilbo Baggins|  50|\n",
      "|      Gandalf|1000|\n",
      "|       Thorin| 195|\n",
      "|        Balin| 178|\n",
      "|         Kili|  77|\n",
      "|       Dwalin| 169|\n",
      "|          Oin| 167|\n",
      "|        Gloin| 158|\n",
      "|         Fili|  82|\n",
      "|       Bombur|null|\n",
      "+-------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Text: string (nullable = true)\n",
      "\n",
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "|Text                                                                                                                        |\n",
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "|\"\\\"Weekly Specials: Worn 2017 Air Jordan IV Retro Motorsport Sz 11 w/ Box In Good Wearable\\\\u2026 https://t.co/cgdDiIKaDR\\\"\"|\n",
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = '../kafka_files/twitterstream_0.jsonl'\n",
    "schema = schema = StructType([\n",
    "        StructField('Text' , StringType(), False),\n",
    "    ])\n",
    "df = spark.read.json(path, columnNameOfCorruptRecord='Text')\n",
    "df.printSchema()\n",
    "df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_ads(text):\n",
    "    return 'https' not in text\n",
    "ads_filter = udf(filter_ads, BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Text|\n",
      "+--------------------+\n",
      "|\"\\\"@AmateurHookup...|\n",
      "|\"\\\"i can't even e...|\n",
      "|\"\\\"@McHavy @StayC...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ads_free = df.filter(ads_filter(df.Text))\n",
    "ads_free.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                Text|               Words|\n",
      "+--------------------+--------------------+\n",
      "|\"\\\"@AmateurHookup...|[amateurhookup, f...|\n",
      "|\"\\\"i can't even e...|[i, can, t, even,...|\n",
      "|\"\\\"@McHavy @StayC...|[mchavy, staycare...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    words = re.sub(\"[^a-zA-Z]\", \" \", text).lower().split()\n",
    "    return words\n",
    "pp_udf = udf(preprocess, ArrayType(StringType()))\n",
    "words = ads_free.withColumn('Words', pp_udf(ads_free.Text))\n",
    "words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                Text|               Words|            filtered|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|\"\\\"@AmateurHookup...|[amateurhookup, f...|[amateurhookup, f...|\n",
      "|\"\\\"i can't even e...|[i, can, t, even,...|[even, explain, s...|\n",
      "|\"\\\"@McHavy @StayC...|[mchavy, staycare...|[mchavy, staycare...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"Words\", outputCol=\"filtered\")\n",
    "removed = remover.transform(words)\n",
    "removed.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_path = '../tmp/{}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                Text|               Words|            filtered|         rawFeatures|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|\"\\\"@AmateurHookup...|[amateurhookup, f...|[amateurhookup, f...|(200,[16,33,61],[...|\n",
      "|\"\\\"i can't even e...|[i, can, t, even,...|[even, explain, s...|(200,[2,6,25,60,7...|\n",
      "|\"\\\"@McHavy @StayC...|[mchavy, staycare...|[mchavy, staycare...|(200,[60,73,74,77...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load trained hashing frequency and transform\n",
    "hf_path = params_path.format('hf')\n",
    "hashingTF = HashingTF.load(hf_path)\n",
    "featureized = hashingTF.transform(removed)\n",
    "featureized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                Text|               Words|            filtered|         rawFeatures|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|\"\\\"@AmateurHookup...|[amateurhookup, f...|[amateurhookup, f...|(200,[16,33,61],[...|(200,[16,33,61],[...|\n",
      "|\"\\\"i can't even e...|[i, can, t, even,...|[even, explain, s...|(200,[2,6,25,60,7...|(200,[2,6,25,60,7...|\n",
      "|\"\\\"@McHavy @StayC...|[mchavy, staycare...|[mchavy, staycare...|(200,[60,73,74,77...|(200,[60,73,74,77...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load trained hashing frequency and transform\n",
    "idf_path = params_path.format('idfmodel')\n",
    "idfmodel = IDFModel.load(idf_path)\n",
    "result = idfmodel.transform(featureized)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|       rawPrediction|prediction|\n",
      "+--------------------+----------+\n",
      "|[50.9842332206184...|       0.0|\n",
      "|[55.7356588277157...|       0.0|\n",
      "|[50.8181693836755...|       0.0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load rf model and predict\n",
    "rf_path = params_path.format('rf')\n",
    "rf = RandomForestClassificationModel.load(rf_path)\n",
    "prediction = rf.transform(result)\n",
    "prediction.select('rawPrediction', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_save = '../tmp/twitterstream_test_prediction.json'\n",
    "prediction.write.json(path_to_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Text: string (nullable = true)\n",
      " |-- Words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- filtered: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- prediction: double (nullable = true)\n",
      " |-- probability: struct (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- rawFeatures: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- rawPrediction: struct (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|                Text|               Words|            features|            filtered|prediction|         probability|         rawFeatures|       rawPrediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|\"\\\"@AmateurHookup...|[amateurhookup, f...|[WrappedArray(16,...|[amateurhookup, f...|       0.0|[1,WrappedArray(0...|[WrappedArray(16,...|[1,WrappedArray(5...|\n",
      "|\"\\\"i can't even e...|[i, can, t, even,...|[WrappedArray(2, ...|[even, explain, s...|       0.0|[1,WrappedArray(0...|[WrappedArray(2, ...|[1,WrappedArray(5...|\n",
      "|\"\\\"@McHavy @StayC...|[mchavy, staycare...|[WrappedArray(60,...|[mchavy, staycare...|       0.0|[1,WrappedArray(0...|[WrappedArray(60,...|[1,WrappedArray(5...|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = spark.read.json(path_to_save)\n",
    "test.printSchema()\n",
    "test.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
