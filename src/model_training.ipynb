{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import string\n",
    "from datetime import datetime\n",
    "import findspark \n",
    "findspark.init()\n",
    "import pyspark as ps\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import array_contains, col, udf, when, coalesce, array\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, CountVectorizer, IDFModel, StopWordsRemover\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, ParamGridBuilder, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = ps.sql.SparkSession.builder \\\n",
    "            .master(\"local[4]\") \\\n",
    "            .appName('Model Training') \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "        StructField('NewIndex' , IntegerType(), False),\n",
    "        StructField('Index' , IntegerType(), False),\n",
    "        StructField('ItemID' , IntegerType(), False),\n",
    "        StructField('Sentiment' , IntegerType(), False),\n",
    "        StructField('SentimentSource' , StringType(), False),\n",
    "        StructField('SentimentText' , StringType(), False),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NewIndex: integer (nullable = true)\n",
      " |-- Index: integer (nullable = true)\n",
      " |-- ItemID: integer (nullable = true)\n",
      " |-- Sentiment: integer (nullable = true)\n",
      " |-- SentimentSource: string (nullable = true)\n",
      " |-- SentimentText: string (nullable = true)\n",
      "\n",
      "+--------+-----+------+---------+---------------+--------------------+\n",
      "|NewIndex|Index|ItemID|Sentiment|SentimentSource|       SentimentText|\n",
      "+--------+-----+------+---------+---------------+--------------------+\n",
      "|       0|    0|     1|        0|   Sentiment140|                 ...|\n",
      "|       1|    1|     2|        0|   Sentiment140|                 ...|\n",
      "|       2|    2|     3|        1|   Sentiment140|              omg...|\n",
      "|       3|    3|     4|        0|   Sentiment140|          .. Omga...|\n",
      "|       4|    4|     5|        0|   Sentiment140|         i think ...|\n",
      "+--------+-----+------+---------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"../data/nokaggle-Sentiment-Analysis-Dataset.csv\"\n",
    "users = spark.read.csv(filename, header=True, schema=schema)\n",
    "users.printSchema()\n",
    "users.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    words = re.sub(\"[^a-zA-Z]\", \" \", text).lower().split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NewIndex: integer (nullable = true)\n",
      " |-- Index: integer (nullable = true)\n",
      " |-- ItemID: integer (nullable = true)\n",
      " |-- Sentiment: integer (nullable = true)\n",
      " |-- SentimentSource: string (nullable = true)\n",
      " |-- SentimentText: string (nullable = true)\n",
      " |-- Words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp_udf = udf(preprocess, ArrayType(StringType()))\n",
    "words = users.withColumn('Words', pp_udf(users.SentimentText))\n",
    "words.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+---------+---------------+--------------------+--------------------+--------------------+\n",
      "|NewIndex|Index|ItemID|Sentiment|SentimentSource|       SentimentText|               Words|            filtered|\n",
      "+--------+-----+------+---------+---------------+--------------------+--------------------+--------------------+\n",
      "|       0|    0|     1|        0|   Sentiment140|                 ...|[is, so, sad, for...|  [sad, apl, friend]|\n",
      "|       1|    1|     2|        0|   Sentiment140|                 ...|[i, missed, the, ...|[missed, new, moo...|\n",
      "|       2|    2|     3|        1|   Sentiment140|              omg...|[omg, its, alread...|      [omg, already]|\n",
      "|       3|    3|     4|        0|   Sentiment140|          .. Omga...|[omgaga, im, sooo...|[omgaga, im, sooo...|\n",
      "|       4|    4|     5|        0|   Sentiment140|         i think ...|[i, think, mi, bf...|[think, mi, bf, c...|\n",
      "|       5|    5|     6|        0|   Sentiment140|         or i jus...|[or, i, just, wor...|       [worry, much]|\n",
      "|       6|    6|     7|        1|   Sentiment140|       Juuuuuuuuu...|[juuuuuuuuuuuuuuu...|[juuuuuuuuuuuuuuu...|\n",
      "|       7|    7|     8|        0|   Sentiment140|       Sunny Agai...|[sunny, again, wo...|[sunny, work, tom...|\n",
      "|       8|    8|     9|        1|   Sentiment140|      handed in m...|[handed, in, my, ...|[handed, uniform,...|\n",
      "|       9|    9|    10|        1|   Sentiment140|      hmmmm.... i...|[hmmmm, i, wonder...|[hmmmm, wonder, n...|\n",
      "|      10|   10|    11|        0|   Sentiment140|      I must thin...|[i, must, think, ...|[must, think, pos...|\n",
      "|      11|   11|    12|        1|   Sentiment140|      thanks to a...|[thanks, to, all,...|[thanks, haters, ...|\n",
      "|      12|   12|    13|        0|   Sentiment140|      this weeken...|[this, weekend, h...|[weekend, sucked,...|\n",
      "|      13|   13|    14|        0|   Sentiment140|     jb isnt show...|[jb, isnt, showin...|[jb, isnt, showin...|\n",
      "|      14|   14|    15|        0|   Sentiment140|     ok thats it ...|[ok, thats, it, y...|    [ok, thats, win]|\n",
      "|      15|   15|    16|        0|   Sentiment140|    &lt;-------- ...|[lt, this, is, th...|[lt, way, feel, r...|\n",
      "|      16|   16|    17|        0|   Sentiment140|    awhhe man.......|[awhhe, man, i, m...|[awhhe, man, comp...|\n",
      "|      17|   17|    18|        1|   Sentiment140|    Feeling stran...|[feeling, strange...|[feeling, strange...|\n",
      "|      18|   18|    19|        0|   Sentiment140|    HUGE roll of ...|[huge, roll, of, ...|[huge, roll, thun...|\n",
      "|      19|   19|    20|        0|   Sentiment140|    I just cut my...|[i, just, cut, my...|[cut, beard, grow...|\n",
      "+--------+-----+------+---------+---------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"Words\", outputCol=\"filtered\")\n",
    "removed = remover.transform(words)\n",
    "removed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------------------+--------------------+--------------------+\n",
      "|ItemID|label|       SentimentText|               Words|            filtered|\n",
      "+------+-----+--------------------+--------------------+--------------------+\n",
      "|     1|    0|                 ...|[is, so, sad, for...|  [sad, apl, friend]|\n",
      "|     2|    0|                 ...|[i, missed, the, ...|[missed, new, moo...|\n",
      "|     3|    1|              omg...|[omg, its, alread...|      [omg, already]|\n",
      "|     4|    0|          .. Omga...|[omgaga, im, sooo...|[omgaga, im, sooo...|\n",
      "|     5|    0|         i think ...|[i, think, mi, bf...|[think, mi, bf, c...|\n",
      "|     6|    0|         or i jus...|[or, i, just, wor...|       [worry, much]|\n",
      "|     7|    1|       Juuuuuuuuu...|[juuuuuuuuuuuuuuu...|[juuuuuuuuuuuuuuu...|\n",
      "|     8|    0|       Sunny Agai...|[sunny, again, wo...|[sunny, work, tom...|\n",
      "|     9|    1|      handed in m...|[handed, in, my, ...|[handed, uniform,...|\n",
      "|    10|    1|      hmmmm.... i...|[hmmmm, i, wonder...|[hmmmm, wonder, n...|\n",
      "|    11|    0|      I must thin...|[i, must, think, ...|[must, think, pos...|\n",
      "|    12|    1|      thanks to a...|[thanks, to, all,...|[thanks, haters, ...|\n",
      "|    13|    0|      this weeken...|[this, weekend, h...|[weekend, sucked,...|\n",
      "|    14|    0|     jb isnt show...|[jb, isnt, showin...|[jb, isnt, showin...|\n",
      "|    15|    0|     ok thats it ...|[ok, thats, it, y...|    [ok, thats, win]|\n",
      "|    16|    0|    &lt;-------- ...|[lt, this, is, th...|[lt, way, feel, r...|\n",
      "|    17|    0|    awhhe man.......|[awhhe, man, i, m...|[awhhe, man, comp...|\n",
      "|    18|    1|    Feeling stran...|[feeling, strange...|[feeling, strange...|\n",
      "|    19|    0|    HUGE roll of ...|[huge, roll, of, ...|[huge, roll, thun...|\n",
      "|    20|    0|    I just cut my...|[i, just, cut, my...|[cut, beard, grow...|\n",
      "+------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered = removed.select('ItemID', col('Sentiment').alias('label'), 'SentimentText', 'Words', 'filtered')\n",
    "filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ItemID: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- SentimentText: string (nullable = true)\n",
      " |-- Words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cast empty array \n",
    "\n",
    "# fill = array().cast(\"array<string>\")\n",
    "# filtered_filled = coalesce(col(\"filtered\"), fill)\n",
    "# filled_featurized = filtered.withColumn(\"filtered\", filtered_filled)\n",
    "# filled_featurized.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|rawFeatures                                                                                          |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|(200,[38,60,193],[1.0,1.0,1.0])                                                                      |\n",
      "|(200,[15,25,81,196],[1.0,1.0,1.0,1.0])                                                               |\n",
      "|(200,[57,184],[1.0,1.0])                                                                             |\n",
      "|(200,[18,56,73,82,102,132,150,155,159,166,169,185],[1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|(200,[72,164,165,169],[1.0,1.0,1.0,1.0])                                                             |\n",
      "|(200,[124,162],[1.0,1.0])                                                                            |\n",
      "|(200,[9,190],[1.0,1.0])                                                                              |\n",
      "|(200,[25,50,101,118,127],[1.0,1.0,1.0,1.0,1.0])                                                      |\n",
      "|(200,[57,62,71,191,197],[1.0,1.0,1.0,1.0,1.0])                                                       |\n",
      "|(200,[84,98,183],[1.0,1.0,1.0])                                                                      |\n",
      "|(200,[1,23,164],[1.0,1.0,1.0])                                                                       |\n",
      "|(200,[5,30,34,138],[1.0,1.0,1.0,1.0])                                                                |\n",
      "|(200,[90,102,186],[1.0,1.0,1.0])                                                                     |\n",
      "|(200,[2,17,116,176],[1.0,1.0,1.0,1.0])                                                               |\n",
      "|(200,[50,84,116],[1.0,1.0,1.0])                                                                      |\n",
      "|(200,[115,134,159,174],[1.0,1.0,1.0,1.0])                                                            |\n",
      "|(200,[22,30,33,65,76,89,106,131,132,187],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                  |\n",
      "|(200,[31,35,41,63,77,88,162,167],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                  |\n",
      "|(200,[4,14,74,198],[1.0,1.0,1.0,1.0])                                                                |\n",
      "|(200,[27,59,63,99,141,153,157,161,196,198],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=200)\n",
    "featurized = hashingTF.transform(filled_featurized)\n",
    "featurized.select('rawFeatures').show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../tmp/hf'\n",
    "hashingTF.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                                                                                                                                                                                          |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(200,[38,60,193],[3.351292892234358,2.7425253655359136,3.2069298628197354])                                                                                                                                                                                                       |\n",
      "|(200,[15,25,81,196],[3.5302978401981506,2.5787462546945012,3.806789299182284,3.230943760152062])                                                                                                                                                                                  |\n",
      "|(200,[57,184],[3.4062058773194526,3.4811037871503667])                                                                                                                                                                                                                            |\n",
      "|(200,[18,56,73,82,102,132,150,155,159,166,169,185],[3.730004761243489,3.499232427988505,3.2076348991583097,5.932750901186225,3.707378652330693,3.2164347103690063,3.1296341759598167,3.2611049833609256,2.357975445745883,4.054514900232662,3.8269361048587265,3.388715924244202])|\n",
      "|(200,[72,164,165,169],[3.2171623052256915,2.6045128481045268,3.225775376524396,3.8269361048587265])                                                                                                                                                                               |\n",
      "|(200,[124,162],[3.236187374489301,3.750669742661097])                                                                                                                                                                                                                             |\n",
      "|(200,[9,190],[3.515987632738829,3.936845597871823])                                                                                                                                                                                                                               |\n",
      "|(200,[25,50,101,118,127],[2.5787462546945012,3.111831853786621,3.1197958080613817,3.6196570984771834,2.745956847791588])                                                                                                                                                          |\n",
      "|(200,[57,62,71,191,197],[3.4062058773194526,2.607716341188582,2.945273045924273,3.5352007679067667,3.4351017754415927])                                                                                                                                                           |\n",
      "|(200,[84,98,183],[3.2116237858330487,3.6251385145864248,3.3895803747142854])                                                                                                                                                                                                      |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurized.cache()\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "model = idf.fit(featurized)\n",
    "result = model.transform(featurized)\n",
    "result.limit(10).select('features').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save idf and idf model\n",
    "idf_path = '../tmp/idf'\n",
    "idf.save(idf_path)\n",
    "idfmodel_path = '../tmp/idfmodel'\n",
    "model.save(idfmodel_path)\n",
    "#load via following\n",
    "#loadedModel = IDFModel.load(idfmodel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32 ms, sys: 0 ns, total: 32 ms\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(numTrees=100, labelCol=\"label\", seed=42)\n",
    "rf_model = rf.fit(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1865.save.\n: java.io.IOException: Path ../tmp/rf already exists. Please use write.overwrite().save(path) to overwrite it.\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:107)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-b7e27d8fc010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../tmp/rf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/ml/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;34m\"\"\"Save this ML instance to the given path, a shortcut of `write().save(path)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/ml/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path should be a basestring, got type %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1865.save.\n: java.io.IOException: Path ../tmp/rf already exists. Please use write.overwrite().save(path) to overwrite it.\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:107)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "path = '../tmp/rf'\n",
    "rf_model.save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1880.load.\n: java.lang.NoSuchMethodException: org.apache.spark.ml.classification.RandomForestClassificationModel.<init>(java.lang.String)\n\tat java.lang.Class.getConstructor0(Class.java:3082)\n\tat java.lang.Class.getConstructor(Class.java:1825)\n\tat org.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:325)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-008d955361e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark/python/pyspark/ml/util.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;34m\"\"\"Reads an ML instance from the input path, a shortcut of `read().load(path)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/ml/util.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path should be a basestring, got type %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clazz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_from_java\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             raise NotImplementedError(\"This Java ML type cannot be loaded into Python currently: %r\"\n",
      "\u001b[0;32m~/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1880.load.\n: java.lang.NoSuchMethodException: org.apache.spark.ml.classification.RandomForestClassificationModel.<init>(java.lang.String)\n\tat java.lang.Class.getConstructor0(Class.java:3082)\n\tat java.lang.Class.getConstructor(Class.java:1825)\n\tat org.apache.spark.ml.util.DefaultParamsReader.load(ReadWrite.scala:325)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "RandomForestClassifier.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SentimentText: string (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+----------+\n",
      "|       SentimentText|         probability|prediction|\n",
      "+--------------------+--------------------+----------+\n",
      "|                 ...|[0.50464022409798...|       0.0|\n",
      "|              omg...|[0.49997696970661...|       1.0|\n",
      "|          .. Omga...|[0.51373803403465...|       0.0|\n",
      "|     jb isnt show...|[0.49997696970661...|       1.0|\n",
      "|    awhhe man.......|[0.48503937730438...|       1.0|\n",
      "+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 220 ms, sys: 48 ms, total: 268 ms\n",
      "Wall time: 7min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Prepare Train Test Split\n",
    "train, test = result.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Configure an ML pipeline, which consists of tree stages: hashingTF, idf and RandomForestClassifier.\n",
    "#remover = StopWordsRemover(inputCol=\"Words\", outputCol=\"filtered\")\n",
    "#hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "rf = RandomForestClassifier(labelCol=\"label\", seed=42)\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "#grid search\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [100]).addGrid(rf.maxDepth, [5]).build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3)  # use 3+ folds in practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(test)\n",
    "selected = prediction.select(\"SentimentText\", \"probability\", \"prediction\")\n",
    "selected.printSchema()\n",
    "selected.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator: estimator to be cross-validated (current: Pipeline_4d209ab67cf8d8f5b65a)\n",
      "estimatorParamMaps: estimator param maps (current: [{Param(parent='RandomForestClassifier_489b806227b5946fa874', name='numTrees', doc='Number of trees to train (>= 1).'): 100, Param(parent='RandomForestClassifier_489b806227b5946fa874', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5}])\n",
      "evaluator: evaluator used to select hyper-parameters that maximize the validator metric (current: BinaryClassificationEvaluator_4b12ad9a627bf23c4fd6)\n",
      "seed: random seed. (default: -8464917656527311148, current: 4738273825629116317)\n"
     ]
    }
   ],
   "source": [
    "print (cvModel.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.645381227448802]\n"
     ]
    }
   ],
   "source": [
    "#cv score\n",
    "print (cvModel.avgMetrics)\n",
    "#test score\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print (\"Test Score is {}\".format(evaluator.evaluate(cvModel.transform(test))))\n",
    "cvModel.getEstimatorParamMaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "cv_path = '../tmp/cv'\n",
    "cvModel.bestModel.save(cv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|    0|(200,[15,25,81,19...|\n",
      "|       1.0|    1|(200,[57,184],[3....|\n",
      "|       0.0|    0|(200,[18,56,73,82...|\n",
      "|       1.0|    0|(200,[2,17,116,17...|\n",
      "|       1.0|    0|(200,[22,30,33,65...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'predictionCol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'predictionCol'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#try graident boosting classifier\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=100)\n",
    "model = gbt.fit(train)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ItemID: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- SentimentText: string (nullable = true)\n",
      " |-- Words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rawFeatures: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n",
      "0.6294383473208521\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "predictions.printSchema()\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
